{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Market Risk — VaR, ES, and Copulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Names of all group members:**\n",
    "- Firstname Lastname (email@example.com)\n",
    "- Firstname Lastname (email@example.com)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "Creates necessary folders and sets hyperparameters for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a package import fails, install it in your environment, e.g.:\n",
    "# %pip install yfinance arch copulae statsmodels seaborn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import copulae\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "# your own script with helper functions, if any\n",
    "# import utils as U\n",
    "\n",
    "# Locate the Project 1 directory to this notebook's working directory\n",
    "PROJECT_DIR = Path.cwd()\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "OUT_DIR = os.path.join(PROJECT_DIR, 'output')\n",
    "for d in [DATA_DIR, OUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "TICKERS = ['AAPL', 'META', 'JPM']\n",
    "START = '2023-01-01'\n",
    "END = '2025-06-30'\n",
    "WINDOW = 252                        # rolling/first-window length in periods (days)\n",
    "ALPHAS = [0.95, 0.99]\n",
    "np.random.seed(0)\n",
    "\n",
    "print('Project dir:', PROJECT_DIR)\n",
    "print('Output ->', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and save Adjusted Close for the tickers over the given range into `data/` (CSV per ticker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "print('Downloading data to', DATA_DIR)\n",
    "for t in TICKERS:\n",
    "    print(f'  -> {t}')\n",
    "    df = yf.download(t, start=START, end=END, progress=False, auto_adjust=False)\n",
    "    if df.empty:\n",
    "        print(f'     Warning: no data for {t}')\n",
    "        continue\n",
    "    out = df.reset_index()\n",
    "    out = out[['Date', 'Adj Close']]\n",
    "    out.to_csv(DATA_DIR / f'{t}.csv', index=False)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the data back from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith('.csv')]\n",
    "frames = []\n",
    "for f in files:\n",
    "    p = os.path.join(DATA_DIR, f)\n",
    "    df = pd.read_csv(p, parse_dates=['Date'])\n",
    "    df = df[['Date', 'Adj Close']]\n",
    "    # Coerce to numeric and drop malformed rows\n",
    "    df['Adj Close'] = pd.to_numeric(df['Adj Close'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date', 'Adj Close'])\n",
    "    df = df.rename(columns={'Adj Close': f.split('.')[0]})\n",
    "    df = df.set_index('Date').sort_index()\n",
    "    frames.append(df)\n",
    "prices = pd.concat(frames, axis=1).dropna(how='all')\n",
    "\n",
    "print(prices.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Empirical stylized facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.  Construct daily log-returns for AAPL, MSFT, JPM; plot series and comment on trends/volatility.\n",
    "2.  Estimate correlation functions of returns and absolute returns across assets and lags 0–25; comment.\n",
    "3.  QQ plots vs Normal; perform Jarque–Bera test and discuss normality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) First-window modeling: VaR, ES, and distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first estimation window W (days) on each asset separately with losses L = −R.\n",
    "Compare: \n",
    "\n",
    "- historical,\n",
    "- Gaussian,\n",
    "- Student-t,\n",
    "- AR(p)+GARCH(1,1) with Normal/Student-t,\n",
    "- Filtered Historical Simulation (FHS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# for the gaussian/student-t fitting, you can use\n",
    "# stats.norm.fit(data) / stats.t.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Rolling-window backtesting of VaR and ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a rolling window of size W to produce 1-step-ahead VaR/ES at 95% and 99% for each method in Exercise 2. Then, implement the following statistical tests:\n",
    "\n",
    "- VaR backtests: Kupiec POF and Christoffersen independence tests.\n",
    "- ES backtest: Acerbi–Székely Z1 test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Unfortunately, it seems like there is no direct implementation of such tests in Python.\n",
    "# Look better into this, or implement them yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Copula fitting (first window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visualize dependence in returns and copula space using pseudo-observations.\n",
    "2. Fit Gaussian and t copulas; report parameters.\n",
    "3. Simulate from fitted copulas and map to empirical marginals; compare with original returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Use copulae package for copula fitting and sampling\n",
    "# cop = copulae.elliptical.GaussianCopula(dim=len(TICKERS))\n",
    "# cop.fit(data)\n",
    "# samples = cop.random(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Portfolio VaR/ES with copulas (rolling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equal-weighted portfolio of AAPL, MSFT, JPM. Compare univariate models (as in Exercise 3) vs copula-based VaR/ES with rolling windows.\n",
    "\n",
    "At each time, fit copulas on last W days, simulate N scenarios, estimate VaR/ES from simulated portfolio returns, then backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
